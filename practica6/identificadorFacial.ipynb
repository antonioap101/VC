{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICION DE FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio 'Images_class_model' se ha creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# ruta donde se almacenarán las imágenes obtenidas para el entreno\n",
    "data_dir = 'Images_class_model'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(f\"El directorio '{data_dir}' se ha creado correctamente.\")\n",
    "else:\n",
    "    print(f\"Error: No se pudo crear el directorio '{data_dir}'.\")\n",
    "\n",
    "def image_capture(class_model_name):\n",
    "    persona_dir = os.path.join(data_dir, class_model_name)\n",
    "    if not os.path.exists(persona_dir):\n",
    "        os.makedirs(persona_dir)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # Guarda la imagen en la carpeta específica de la persona\n",
    "            cv2.imwrite(f'{persona_dir}/{class_model_name}_{count}.png', roi)\n",
    "            count += 1\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or count >= 150:\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def train_model(data_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for person in os.listdir(data_dir):\n",
    "        if person.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        label = person\n",
    "        person_dir = os.path.join(data_dir, person)\n",
    "\n",
    "        for file in os.listdir(person_dir):\n",
    "            if file.endswith('.png'):\n",
    "                img_path = os.path.join(person_dir, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (100, 100))\n",
    "                data.append(np.ravel(img))\n",
    "                labels.append(label)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Hay al menos dos clases para entrenar el clasificador SVM\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        n_components = 50\n",
    "        pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        classifier = SVC(kernel='rbf', class_weight='balanced')\n",
    "        classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_pca)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "        return classifier, pca\n",
    "    else:\n",
    "        print(\"Error: El uso del clasificador SVM requiere de almenos 2 clases.\")\n",
    "        return None, None\n",
    "\n",
    "def real_time_recognition(classifier, pca):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(roi, (100, 100))\n",
    "\n",
    "\n",
    "            roi_pca = pca.transform(np.ravel(roi).reshape(1, -1))\n",
    "\n",
    "\n",
    "            label = classifier.predict(roi_pca)[0]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Model: {label}', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREADOR DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:30:13.262 Python[10822:379710] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "# Capturar imágenes para el dataset\n",
    "name = 'Modesto'\n",
    "image_capture(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb Celda 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mImages_class_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classifier, pca \u001b[39m=\u001b[39m train_model(data_dir)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m real_time_recognition(classifier, pca)\n",
      "\u001b[1;32m/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb Celda 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m video_capture \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m video_capture\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     faces \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(cv2\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mhaarcascades \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdetectMultiScale(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m         gray,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m         scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m         flags\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mCASCADE_SCALE_IMAGE\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/emmartel/Desktop/Universidad/VC/VC/practica6/IdentificadorFacial.ipynb#W2sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo y realizar el reconocimiento facial en tiempo real\n",
    "data_dir = 'Images_class_model'\n",
    "classifier, pca = train_model(data_dir)\n",
    "real_time_recognition(classifier, pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
