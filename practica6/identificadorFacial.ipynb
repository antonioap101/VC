{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICION DE FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio 'Images_class_model' se ha creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# ruta donde se almacenarán las imágenes obtenidas para el entreno\n",
    "data_dir = 'Images_class_model'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(f\"El directorio '{data_dir}' se ha creado correctamente.\")\n",
    "else:\n",
    "    print(f\"Error: No se pudo crear el directorio '{data_dir}'.\")\n",
    "\n",
    "def image_capture(class_model_name):\n",
    "    persona_dir = os.path.join(data_dir, class_model_name)\n",
    "    # extra_faces_dir = os.path.join(data_dir, 'extra_faces')  # Carpeta para caras adicionales\n",
    "    if not os.path.exists(persona_dir):\n",
    "        os.makedirs(persona_dir)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        # Solo incrementar el contador si se detecta al menos una cara\n",
    "        if len(faces) > 0:\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                # Filtrar caras por tamaño de contorno\n",
    "                if w >= 300 and w <= 600 and h >= 300 and h <= 600:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "                    # Determinar la ruta de la carpeta\n",
    "                    target_dir = persona_dir\n",
    "                    # Guardar la imagen en la carpeta específica\n",
    "                    cv2.imwrite(f'{target_dir}/{class_model_name}_{count}.png', roi)\n",
    "                    count += 1\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or count >= 150:\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def train_model(data_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for person in os.listdir(data_dir):\n",
    "        if person.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        label = person\n",
    "        person_dir = os.path.join(data_dir, person)\n",
    "\n",
    "        for file in os.listdir(person_dir):\n",
    "            if file.endswith('.png'):\n",
    "                img_path = os.path.join(person_dir, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (100, 100))\n",
    "                data.append(np.ravel(img))\n",
    "                labels.append(label)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Hay al menos dos clases para entrenar el clasificador SVM\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        n_components = 50\n",
    "        pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        classifier = SVC(kernel='rbf', class_weight='balanced')\n",
    "        classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_pca)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "        return classifier, pca\n",
    "    else:\n",
    "        print(\"Error: El uso del clasificador SVM requiere de almenos 2 clases.\")\n",
    "        return None, None\n",
    "\n",
    "def real_time_recognition(classifier, pca):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(roi, (100, 100))\n",
    "\n",
    "\n",
    "            roi_pca = pca.transform(np.ravel(roi).reshape(1, -1))\n",
    "\n",
    "\n",
    "            label = classifier.predict(roi_pca)[0]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Model: {label}', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREADOR DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar imágenes para el dataset\n",
    "name = 'Antonio'\n",
    "image_capture(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /Users/xperience/GHA-OpenCV-Python/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImages_class_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m classifier, pca \u001b[38;5;241m=\u001b[39m train_model(data_dir)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mreal_time_recognition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 111\u001b[0m, in \u001b[0;36mreal_time_recognition\u001b[0;34m(classifier, pca)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m video_capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 111\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     faces \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetectMultiScale(\n\u001b[1;32m    114\u001b[0m         gray,\n\u001b[1;32m    115\u001b[0m         scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m         flags\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mCASCADE_SCALE_IMAGE\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /Users/xperience/GHA-OpenCV-Python/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo y realizar el reconocimiento facial en tiempo real\n",
    "data_dir = 'Images_class_model'\n",
    "classifier, pca = train_model(data_dir)\n",
    "real_time_recognition(classifier, pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
