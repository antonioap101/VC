{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision por Computador: Práctica 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juego razas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables e importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle eastern: (612, 612, 4)\n",
      "asian: (512, 512, 4)\n",
      "indian: (724, 600, 4)\n",
      "latino hispanic: (1790, 1920, 4)\n",
      "black: (1595, 1920, 4)\n",
      "white: (375, 385, 4)\n",
      "default: (375, 385, 4)\n"
     ]
    }
   ],
   "source": [
    "# Importa los modulos necesarios\n",
    "import cv2\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Cargamos los gorros guardados\n",
    "gorros = {\n",
    "        'middle eastern': cv2.imread('assets/gorro_ruso.png', cv2.IMREAD_UNCHANGED),\n",
    "        'asian': cv2.imread('assets/gorro_chino.png', cv2.IMREAD_UNCHANGED),\n",
    "        'indian': cv2.imread('assets/gorro_indio.png', cv2.IMREAD_UNCHANGED),\n",
    "        'latino hispanic': cv2.imread('assets/gorro_mexicano.png', cv2.IMREAD_UNCHANGED),\n",
    "        'black': cv2.imread('assets/gorro_negro.png', cv2.IMREAD_UNCHANGED),\n",
    "        'white': cv2.imread('assets/gorro_blanco.png', cv2.IMREAD_UNCHANGED),\n",
    "        'default': cv2.imread('assets/gorro_blanco.png', cv2.IMREAD_UNCHANGED)\n",
    "        }\n",
    "\n",
    "for nombre, gorro in gorros.items():\n",
    "    print(f\"{nombre}: {gorro.shape}\")  # Debería mostrar algo como (altura, anchura, 4)\n",
    "\n",
    "\n",
    "\n",
    "class Button:\n",
    "    def __init__(self, x1, y1, size=\"normal\"):\n",
    "        if size == \"normal\":\n",
    "            self.width = 245\n",
    "            self.height = 105\n",
    "        elif size == \"small\":\n",
    "            self.width = 160\n",
    "            self.height = 80\n",
    "        elif size == \"squared\":\n",
    "            self.width = 110\n",
    "            self.height = 110\n",
    "        else:\n",
    "            raise ValueError(\"Tamaño de botón no válido\")\n",
    "        \n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        \n",
    "    def get_coordinates(self):\n",
    "        x2 = self.x1 + self.width\n",
    "        y2 = self.y1 + self.height\n",
    "        return (self.x1, self.y1, x2, y2)\n",
    "\n",
    "    \n",
    "botones_menu = {\n",
    "    \"ELEGIR\": Button(x1=50, y1=285).get_coordinates(),  # (x1, y1, x2, y2) (35, 195, 210, 270)\n",
    "    \"DETECTAR\": Button(x1=325, y1=285).get_coordinates(),\n",
    "    \"SALIR\": Button(x1=600, y1=285).get_coordinates(),\n",
    "}\n",
    "\n",
    "botones_detectar = {\n",
    "    \"MENU\": Button(x1=35, y1=580, size=\"small\").get_coordinates(),\n",
    "    \"SALIR\": Button(x1=710, y1=580, size=\"small\").get_coordinates()\n",
    "}\n",
    "\n",
    "botones_elegir = {\n",
    "    \"MENU\": Button(x1=35, y1=15, size=\"small\").get_coordinates(),\n",
    "    \"SALIR\": Button(x1=710, y1=15, size=\"small\").get_coordinates()\n",
    "}\n",
    "\n",
    "botones_cambiar_sombrero = {\n",
    "    'black': Button(x1=55, y1=545, size=\"squared\").get_coordinates(),\n",
    "    'indian': Button(x1=190, y1=545, size=\"squared\").get_coordinates(),\n",
    "    'asian':Button(x1=325, y1=545, size=\"squared\").get_coordinates(),\n",
    "    'latino hispanic': Button(x1=460, y1=545, size=\"squared\").get_coordinates(),\n",
    "    'middle eastern':Button(x1=595, y1=545, size=\"squared\").get_coordinates(),\n",
    "    'white': Button(x1=735, y1=545, size=\"squared\").get_coordinates(),\n",
    "}\n",
    "\n",
    "# Cargar la imagen de los botones_menu \n",
    "pantalla_menu = cv2.imread('assets/pantalla_menu.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Cargar la imagen de los botones_detectar\n",
    "pantalla_detectar = cv2.imread('assets/pantalla_detectar.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Cargar las imágenes de fondo para cada selección de gorro\n",
    "pantallas_elegir = {\n",
    "    'white': cv2.imread('assets/GorroBlancoSeleccionado.png', cv2.IMREAD_UNCHANGED),\n",
    "    'indian': cv2.imread('assets/GorroIndioSeleccionado.png', cv2.IMREAD_UNCHANGED),\n",
    "    'asian': cv2.imread('assets/GorroChinoSeleccionado.png', cv2.IMREAD_UNCHANGED),\n",
    "    'latino hispanic': cv2.imread('assets/GorroMexicanoSeleccionado.png', cv2.IMREAD_UNCHANGED),\n",
    "    'black': cv2.imread('assets/GorroNegroSeleccionado.png', cv2.IMREAD_UNCHANGED),\n",
    "    'middle eastern': cv2.imread('assets/GorroRusoSeleccionado.png', cv2.IMREAD_UNCHANGED)\n",
    "}\n",
    "\n",
    "# Estado del juego\n",
    "estado = \"MENU\"  # Estados posibles: \"MENU\", \"DETECTAR\", \"ELEGIR\", \"SALIR\"\n",
    "# Diccionario para almacenar el gorro seleccionado\n",
    "gorro_seleccionado = 'white'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superponer_imagen(fondo, superposicion):\n",
    "    \n",
    "    superposicion = cv2.resize(superposicion, (fondo.shape[1], fondo.shape[0]))\n",
    "    # Extraer el canal alpha de la superposición\n",
    "    alpha_s = superposicion[:, :, 3] / 255.0\n",
    "    alpha_l = 1 - alpha_s\n",
    "\n",
    "    # Superponer la imagen\n",
    "    for c in range(0, 3):\n",
    "        fondo[:, :, c] = (alpha_s * superposicion[:, :, c] +\n",
    "                          alpha_l * fondo[:, :, c])\n",
    "        \n",
    "def superponer_gorro(frame, gorro, x, y, w, h):\n",
    "    gorro_redimensionado = cv2.resize(gorro, (w, int(h / 2)))\n",
    "    for i in range(gorro_redimensionado.shape[0]):\n",
    "        for j in range(gorro_redimensionado.shape[1]):\n",
    "            if gorro_redimensionado[i, j, 3] != 0:\n",
    "                frame[y - int(h / 2) + i, x + j, :] = gorro_redimensionado[i, j, 0:3]\n",
    "    return frame\n",
    "\n",
    "def __detectar(frame):\n",
    "    # Variable estática para el conteo de frames\n",
    "    if 'contador_frames' not in detectar.__dict__:\n",
    "        detectar.contador_frames = 0  # Inicializar en la primera llamada\n",
    "    if 'obj' not in detectar.__dict__:\n",
    "        detectar.obj = DeepFace.analyze(img_path=frame, enforce_detection=False, actions=['race'])  # Almacenar los últimos resultados de DeepFace\n",
    "        \n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    font, fontScale, color, thickness, pos = cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, (50, 50)\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "\n",
    "    # Incrementar contador de frames\n",
    "    detectar.contador_frames += 1\n",
    "    \n",
    "    # Aplicar DeepFace solo cada 50 frames\n",
    "    if detectar.contador_frames % 40 == 0 and len(faces) > 0:\n",
    "        # Analizar todas las caras a la vez\n",
    "        detectar.obj = DeepFace.analyze(img_path=frame, enforce_detection=False, actions=['race'])\n",
    "        print(detectar.obj)\n",
    "        #print(obj)\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        if i < len(detectar.obj):\n",
    "            # Obtenemos la raza dominante para la cara actual\n",
    "            raza_dominante = detectar.obj[i][\"dominant_race\"]\n",
    "            gorro = gorros.get(raza_dominante, gorros['default'])\n",
    "            \n",
    "            frame = superponer_gorro(frame, gorro, x, y, w, h)\n",
    "            #cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            #cv2.putText(frame, raza_dominante, pos, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        else:\n",
    "            break  # No hay más resultados de DeepFace para procesar\n",
    "        \n",
    "    return frame\n",
    "\n",
    "def detectar(frame):\n",
    "    if 'contador_frames' not in detectar.__dict__:\n",
    "        detectar.contador_frames = 0  # Inicializar en la primera llamada\n",
    "    if 'obj' not in detectar.__dict__:\n",
    "        detectar.obj = DeepFace.analyze(img_path=frame, enforce_detection=False, actions=['race'])  # Almacenar los últimos resultados de DeepFace\n",
    "    \n",
    "    # Incrementar contador de frames\n",
    "    detectar.contador_frames += 1\n",
    "    \n",
    "    # Aplicar DeepFace solo cada 40 frames\n",
    "    if detectar.contador_frames % 5 == 0:\n",
    "        # Analizar todas las caras a la vez\n",
    "        detectar.obj = DeepFace.analyze(img_path=frame, enforce_detection=False, actions=['race'])\n",
    "        print(detectar.obj)\n",
    "\n",
    "    if detectar.obj:\n",
    "        for resultado in detectar.obj:\n",
    "            confianza = resultado['face_confidence']\n",
    "            if confianza >= 2:\n",
    "                # Extraer la información de la región y la raza dominante\n",
    "                region = resultado['region']\n",
    "                raza_dominante = resultado['dominant_race']\n",
    "    \n",
    "                # Coordenadas de la cara\n",
    "                x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "    \n",
    "                # Seleccionar el gorro basado en la raza dominante\n",
    "                gorro = gorros.get(raza_dominante, gorros['default'])\n",
    "    \n",
    "                # Superponer el gorro en la cara detectada\n",
    "                frame = superponer_gorro(frame, gorro, x, y, w, h)\n",
    "                # Opcional: Dibujar rectángulo y texto\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # font, fontScale, color, thickness, pos = cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, (50, 50)\n",
    "                # cv2.putText(frame, raza_dominante, (x, y - 10), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        \n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def elegir(frame):\n",
    "    global gorro_seleccionado\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=6, minSize=(150, 150))\n",
    "\n",
    "    # Superponer el gorro seleccionado sobre cada cara detectada\n",
    "    for (x, y, w, h) in faces:\n",
    "        if gorro_seleccionado is not None:\n",
    "            gorro = gorros[gorro_seleccionado]\n",
    "            frame = superponer_gorro(frame, gorro, x, y, w, h)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def salir():\n",
    "    print(\"Saliendo del juego\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Función para dibujar los botones_menu en el frame\n",
    "def dibujar_botones(frame):\n",
    "    global gorro_seleccionado\n",
    "    if estado == \"MENU\":\n",
    "        superponer_imagen(fondo=frame, superposicion=pantalla_menu)\n",
    "        for nombre_boton, (x1, y1, x2, y2) in botones_menu.items():\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    if estado == \"DETECTAR\":\n",
    "        superponer_imagen(fondo=frame, superposicion=pantalla_detectar)\n",
    "        for nombre_boton, (x1, y1, x2, y2) in botones_detectar.items():\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    if estado == \"ELEGIR\":\n",
    "        superponer_imagen(fondo=frame, superposicion=pantallas_elegir[gorro_seleccionado])        \n",
    "        for nombre_boton, (x1, y1, x2, y2) in botones_elegir.items():\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "        for nombre_boton, (x1, y1, x2, y2) in botones_cambiar_sombrero.items():\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)     \n",
    "        \n",
    "# Función de devolución de llamada para manejar eventos de clic del mouse\n",
    "def clic_mouse(event, x, y, flags, param):\n",
    "    global estado, gorro_seleccionado\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if estado == \"MENU\":\n",
    "            # Aquí detectas en qué botón se hizo clic y actualizas el estado\n",
    "            for nombre_boton, (x1, y1, x2, y2) in botones_menu.items():\n",
    "                if x1 < x < x2 and y1 < y < y2:\n",
    "                    estado = nombre_boton  # Actualiza el estado basado en el botón presionado\n",
    "        elif estado == \"DETECTAR\":\n",
    "            for nombre_boton, (x1, y1, x2, y2) in botones_detectar.items():\n",
    "                if x1 < x < x2 and y1 < y < y2:  \n",
    "                    estado = nombre_boton  # Actualiza el estado basado en el botón presionado\n",
    "        elif estado == \"ELEGIR\":\n",
    "            for nombre_gorro, (x1, y1, x2, y2) in botones_cambiar_sombrero.items():\n",
    "                if x1 < x < x2 and y1 < y < y2:\n",
    "                    gorro_seleccionado = nombre_gorro\n",
    "                    break\n",
    "            for nombre_boton, (x1, y1, x2, y2) in botones_elegir.items():\n",
    "                if x1 < x < x2 and y1 < y < y2:\n",
    "                    estado = nombre_boton  # Actualiza el estado basado en el botón presionado\n",
    "                    break\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolución de la pantalla: 900x699\n",
      "[{'race': {'asian': 34.18595100557512, 'indian': 2.270200238835826, 'black': 6.934854801586557, 'white': 39.46852323225279, 'middle eastern': 7.637506433576729, 'latino hispanic': 9.502961307940561}, 'dominant_race': 'white', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 26.274041907432192, 'indian': 18.660373607896187, 'black': 38.44411304259974, 'white': 1.8306519064695779, 'middle eastern': 1.8772273512022108, 'latino hispanic': 12.913597399806822}, 'dominant_race': 'black', 'region': {'x': 458, 'y': 110, 'w': 246, 'h': 246}, 'face_confidence': 7.889253028144594}]\n",
      "[{'race': {'asian': 19.383516087112895, 'indian': 14.384649469298187, 'black': 55.01344144184095, 'white': 1.1526138079030743, 'middle eastern': 1.2317969857994335, 'latino hispanic': 8.83397578192046}, 'dominant_race': 'black', 'region': {'x': 478, 'y': 101, 'w': 243, 'h': 243}, 'face_confidence': 9.253905119781848}]\n",
      "[{'race': {'asian': 51.758772134780884, 'indian': 0.5334839690476656, 'black': 1.3887089677155018, 'white': 36.39269769191742, 'middle eastern': 4.00143526494503, 'latino hispanic': 5.924901366233826}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 24.012017367837743, 'indian': 0.9898684670187871, 'black': 2.8291093538273153, 'white': 58.140306694471036, 'middle eastern': 5.463268701640522, 'latino hispanic': 8.565427831956407}, 'dominant_race': 'white', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 17.157435417175293, 'indian': 37.08852827548981, 'black': 17.21336841583252, 'white': 4.876559600234032, 'middle eastern': 5.263511091470718, 'latino hispanic': 18.400603532791138}, 'dominant_race': 'indian', 'region': {'x': 513, 'y': 121, 'w': 232, 'h': 232}, 'face_confidence': 3.7729421091498807}]\n",
      "[{'race': {'asian': 61.06861001662076, 'indian': 0.7479389178269457, 'black': 3.6827193905543916, 'white': 26.311703104478305, 'middle eastern': 2.431037049355331, 'latino hispanic': 5.757993430375661}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 24.706150591373444, 'indian': 19.140048325061798, 'black': 14.828522503376007, 'white': 8.66369977593422, 'middle eastern': 9.827987849712372, 'latino hispanic': 22.83359169960022}, 'dominant_race': 'asian', 'region': {'x': 530, 'y': 117, 'w': 228, 'h': 228}, 'face_confidence': 8.998905187123455}]\n",
      "[{'race': {'asian': 31.83984376909211, 'indian': 18.589328993638873, 'black': 16.53457682912626, 'white': 5.6988664628426475, 'middle eastern': 5.4440953798180365, 'latino hispanic': 21.89328558525019}, 'dominant_race': 'asian', 'region': {'x': 494, 'y': 126, 'w': 226, 'h': 226}, 'face_confidence': 6.697114028444048}]\n",
      "[{'race': {'asian': 32.581045185389826, 'indian': 16.177752088174348, 'black': 14.368883631758907, 'white': 7.352859220079137, 'middle eastern': 6.893779003249348, 'latino hispanic': 22.62568757687137}, 'dominant_race': 'asian', 'region': {'x': 511, 'y': 113, 'w': 231, 'h': 231}, 'face_confidence': 7.619091984524857}]\n",
      "[{'race': {'asian': 19.748353958129883, 'indian': 15.186327695846558, 'black': 43.08587610721588, 'white': 3.846997767686844, 'middle eastern': 3.2659705728292465, 'latino hispanic': 14.866474270820618}, 'dominant_race': 'black', 'region': {'x': 500, 'y': 129, 'w': 239, 'h': 239}, 'face_confidence': 6.419673059252091}]\n",
      "[{'race': {'asian': 51.04860371640943, 'indian': 0.752618720911069, 'black': 2.4303566250417603, 'white': 33.94662940184053, 'middle eastern': 2.845653129854985, 'latino hispanic': 8.976142643460193}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 6.008327351013106, 'indian': 5.490347279947672, 'black': 84.44320970096703, 'white': 0.4744020390542792, 'middle eastern': 0.26774884599433496, 'latino hispanic': 3.315966971631881}, 'dominant_race': 'black', 'region': {'x': 547, 'y': 111, 'w': 222, 'h': 222}, 'face_confidence': 4.711406063404866}]\n",
      "[{'race': {'asian': 34.210022342802425, 'indian': 0.9633132830746939, 'black': 2.08168954889116, 'white': 49.39123090453332, 'middle eastern': 5.167318070967083, 'latino hispanic': 8.18643246212199}, 'dominant_race': 'white', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 77.8630256652832, 'indian': 0.5574698094278574, 'black': 6.669048219919205, 'white': 7.560152560472488, 'middle eastern': 0.9214692749083042, 'latino hispanic': 6.428829580545425}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 73.6490547657013, 'indian': 0.30600063037127256, 'black': 1.3027133420109749, 'white': 19.29100751876831, 'middle eastern': 1.5590954571962357, 'latino hispanic': 3.89212965965271}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 76.90260089604844, 'indian': 0.47386585673798837, 'black': 2.191349789041306, 'white': 13.514315961084847, 'middle eastern': 1.6937468044463628, 'latino hispanic': 5.224117386446311}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 73.39284420013428, 'indian': 0.4703063052147627, 'black': 2.3886464536190033, 'white': 16.105088591575623, 'middle eastern': 1.969323307275772, 'latino hispanic': 5.673791095614433}, 'dominant_race': 'asian', 'region': {'x': 0, 'y': 0, 'w': 1280, 'h': 640}, 'face_confidence': 0}]\n",
      "[{'race': {'asian': 31.16984738944142, 'indian': 17.313583769033404, 'black': 20.90874563559838, 'white': 5.296609064532407, 'middle eastern': 4.2020363154454605, 'latino hispanic': 21.1091811787106}, 'dominant_race': 'asian', 'region': {'x': 477, 'y': 85, 'w': 254, 'h': 254}, 'face_confidence': 7.862849015218671}]\n",
      "[{'race': {'asian': 23.614609158909868, 'indian': 21.964989421665038, 'black': 38.43797078358953, 'white': 1.4916450674322288, 'middle eastern': 1.4384459630218722, 'latino hispanic': 13.052343610068775}, 'dominant_race': 'black', 'region': {'x': 477, 'y': 109, 'w': 242, 'h': 242}, 'face_confidence': 5.281744108884595}]\n",
      "[{'race': {'asian': 48.40888977050781, 'indian': 15.132248401641846, 'black': 18.39689463376999, 'white': 1.9112665206193924, 'middle eastern': 0.8523068390786648, 'latino hispanic': 15.298394858837128}, 'dominant_race': 'asian', 'region': {'x': 475, 'y': 115, 'w': 240, 'h': 240}, 'face_confidence': 7.5644761409494095}]\n",
      "[{'race': {'asian': 36.96083128452301, 'indian': 16.311585903167725, 'black': 11.937085539102554, 'white': 7.301203906536102, 'middle eastern': 5.940694361925125, 'latino hispanic': 21.54860496520996}, 'dominant_race': 'asian', 'region': {'x': 492, 'y': 110, 'w': 250, 'h': 250}, 'face_confidence': 7.140203072107397}]\n",
      "[{'race': {'asian': 14.274810254573822, 'indian': 19.94139701128006, 'black': 44.55794394016266, 'white': 3.3841852098703384, 'middle eastern': 4.921875894069672, 'latino hispanic': 12.919783592224121}, 'dominant_race': 'black', 'region': {'x': 507, 'y': 114, 'w': 267, 'h': 267}, 'face_confidence': 5.255424159753602}]\n",
      "[{'race': {'asian': 28.292104601860046, 'indian': 20.381098985671997, 'black': 26.779940724372864, 'white': 3.7813596427440643, 'middle eastern': 3.719634562730789, 'latino hispanic': 17.045858502388}, 'dominant_race': 'asian', 'region': {'x': 511, 'y': 158, 'w': 227, 'h': 227}, 'face_confidence': 3.3745209144544788}]\n",
      "[{'race': {'asian': 14.246197044849396, 'indian': 15.98997712135315, 'black': 34.203359484672546, 'white': 6.86829686164856, 'middle eastern': 9.506187587976456, 'latino hispanic': 19.185984134674072}, 'dominant_race': 'black', 'region': {'x': 521, 'y': 133, 'w': 246, 'h': 246}, 'face_confidence': 4.328813094296493}]\n",
      "[{'race': {'asian': 19.607657194137573, 'indian': 17.16681569814682, 'black': 44.5096492767334, 'white': 1.8825992941856384, 'middle eastern': 1.6481978818774223, 'latino hispanic': 15.185081958770752}, 'dominant_race': 'black', 'region': {'x': 510, 'y': 139, 'w': 239, 'h': 239}, 'face_confidence': 5.4364620361011475}]\n",
      "[{'race': {'asian': 46.27213180065155, 'indian': 13.514885306358337, 'black': 4.059484601020813, 'white': 7.033267617225647, 'middle eastern': 3.6408189684152603, 'latino hispanic': 25.4794180393219}, 'dominant_race': 'asian', 'region': {'x': 503, 'y': 142, 'w': 231, 'h': 231}, 'face_confidence': 5.4989060199586675}]\n",
      "[{'race': {'asian': 25.254605725682122, 'indian': 15.849923542137358, 'black': 9.098700976294337, 'white': 12.568029020311178, 'middle eastern': 14.469831554283592, 'latino hispanic': 22.758909926349517}, 'dominant_race': 'asian', 'region': {'x': 489, 'y': 108, 'w': 241, 'h': 241}, 'face_confidence': 6.300877036293969}]\n",
      "[{'race': {'asian': 30.96167743206024, 'indian': 14.48783427476883, 'black': 10.190170258283615, 'white': 10.583318769931793, 'middle eastern': 10.143089294433594, 'latino hispanic': 23.633907735347748}, 'dominant_race': 'asian', 'region': {'x': 489, 'y': 122, 'w': 233, 'h': 233}, 'face_confidence': 7.339366034255363}]\n",
      "[{'race': {'asian': 0.3273734432609745, 'indian': 2.3931915812860036, 'black': 96.94673455396479, 'white': 0.007073885965666358, 'middle eastern': 0.009797805538057248, 'latino hispanic': 0.3158219247821659}, 'dominant_race': 'black', 'region': {'x': 525, 'y': 111, 'w': 222, 'h': 222}, 'face_confidence': 8.42996308032889}]\n",
      "[{'race': {'asian': 4.239208623766899, 'indian': 0.2681719372048974, 'black': 0.03835349343717098, 'white': 91.02632999420166, 'middle eastern': 2.8952885419130325, 'latino hispanic': 1.5326451510190964}, 'dominant_race': 'white', 'region': {'x': 585, 'y': 120, 'w': 106, 'h': 106}, 'face_confidence': 4.361552128510084}, {'race': {'asian': 2.8902899473905563, 'indian': 4.812363907694817, 'black': 85.95267534255981, 'white': 0.6574689410626888, 'middle eastern': 0.6220209412276745, 'latino hispanic': 5.0651803612709045}, 'dominant_race': 'black', 'region': {'x': 473, 'y': 101, 'w': 252, 'h': 252}, 'face_confidence': 4.655797089333646}]\n"
     ]
    }
   ],
   "source": [
    "# ==================================CÓDIGO PRINCIPAL==================================            \n",
    "\n",
    "def iniciar_juego(fuente_video=0):\n",
    "    global estado\n",
    "    estado = \"MENU\"\n",
    "    # Inicializar la fuente de video (cámara o archivo de video)\n",
    "    vid = cv2.VideoCapture(fuente_video)\n",
    "\n",
    "    if not vid.isOpened():\n",
    "        print(\"No se pudo abrir la fuente de video:\", fuente_video)\n",
    "        return\n",
    "\n",
    "     # Asumir que todas las pantallas superpuestas tienen la misma resolución\n",
    "    altura_pantalla, ancho_pantalla = pantalla_menu.shape[:2]\n",
    "    \n",
    "     # Imprimir la resolución del frame actual\n",
    "    print(f\"Resolución de la pantalla: {ancho_pantalla}x{altura_pantalla}\")\n",
    "\n",
    "    # Establecer la función de callback para el mouse\n",
    "    cv2.namedWindow('Juego')\n",
    "    cv2.setMouseCallback('Juego', clic_mouse)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"No se pudo leer el frame. Fin del video o error de lectura.\")\n",
    "            break\n",
    "        \n",
    "        # Redimensionamos el frame para que sea del tamaño de la pantalla de juego\n",
    "        #frame = cv2.resize(frame, (ancho_pantalla,altura_pantalla))\n",
    "        #print(f\"Resolución del frame: {frame.shape[1]}x{frame.shape[0]}\")\n",
    "        \n",
    "        # Manejar el estado del juego\n",
    "        \n",
    "        if estado == \"MENU\":\n",
    "            dibujar_botones(frame)\n",
    "        elif estado == \"DETECTAR\":\n",
    "            detectar(frame) \n",
    "            dibujar_botones(frame)\n",
    "        elif estado == \"ELEGIR\":\n",
    "            elegir(frame)  \n",
    "            dibujar_botones(frame)\n",
    "        elif estado == \"SALIR\":\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Juego', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        \n",
    "                \n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejemplo de cómo usar la función\n",
    "# Para usar la cámara por defecto\n",
    "#iniciar_juego()\n",
    "\n",
    "\n",
    "# Para usar un archivo de vídeo\n",
    "iniciar_juego('./video_test_5.mp4')\n",
    "\n",
    "#iniciar_juego('./video_test_4.mp4')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
